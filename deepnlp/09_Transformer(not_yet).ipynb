{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fba84159798>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab;tagger=Mecab()\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = list(map(lambda w: to_ix[w], seq))\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIM = 512 # d_model = d_k = d_v\n",
    "N = 6 # num of layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0e4==10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "math.lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_timing_signal_1d(x, min_timescale=1.0, max_timescale=1.0e4):\n",
    "  \"\"\"Adds a bunch of sinusoids of different frequencies to a Tensor.\n",
    "  Each channel of the input Tensor is incremented by a sinusoid of a different\n",
    "  frequency and phase.\n",
    "  This allows attention to learn to use absolute and relative positions.\n",
    "  Timing signals should be added to some precursors of both the query and the\n",
    "  memory inputs to attention.\n",
    "  The use of relative position is possible because sin(x+y) and cos(x+y) can be\n",
    "  experessed in terms of y, sin(x) and cos(x).\n",
    "  In particular, we use a geometric sequence of timescales starting with\n",
    "  min_timescale and ending with max_timescale.  The number of different\n",
    "  timescales is equal to channels / 2. For each timescale, we\n",
    "  generate the two sinusoidal signals sin(timestep/timescale) and\n",
    "  cos(timestep/timescale).  All of these sinusoids are concatenated in\n",
    "  the channels dimension.\n",
    "  Args:\n",
    "    x: a Tensor with shape [batch, length, channels]\n",
    "    min_timescale: a float\n",
    "    max_timescale: a float\n",
    "  Returns:\n",
    "    a Tensor the same shape as x.\n",
    "  \"\"\"\n",
    "  length = tf.shape(x)[1]\n",
    "  channels = tf.shape(x)[2]\n",
    "  position = tf.to_float(tf.range(length))\n",
    "  num_timescales = channels // 2\n",
    "  log_timescale_increment = (\n",
    "      math.log(float(max_timescale) / float(min_timescale)) /\n",
    "      (tf.to_float(num_timescales) - 1))\n",
    "  inv_timescales = min_timescale * tf.exp(\n",
    "      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n",
    "  scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)\n",
    "  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n",
    "  signal = tf.pad(signal, [[0, 0], [0, tf.mod(channels, 2)]])\n",
    "  signal = tf.reshape(signal, [1, length, channels])\n",
    "  return x + signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.from_numpy(np.array([1.0,2.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=6):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "    \n",
    "    def positional_embedding(self, x, min_timescale=1.0, max_timescale=1.0e4):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "            x: a Tensor with shape [batch, length, channels]\n",
    "            min_timescale: a float\n",
    "            max_timescale: a float\n",
    "          Returns:\n",
    "            a Tensor the same shape as x.\n",
    "        \"\"\"\n",
    "        return x\n",
    "    \n",
    "    def layer_norm(self, a, gain,bias):\n",
    "        \"\"\"\n",
    "        a = Batch_size*Model_dim\n",
    "        g = gain_parameter\n",
    "        \"\"\"\n",
    "        mu = torch.mean(a, dim=1)\n",
    "        sigma = torch.std(a, dim=1)\n",
    "        \n",
    "        return (gain/sigma)*(a-mu)+bias\n",
    "    \n",
    "    def residual(self,l_input,l_output):\n",
    "        return self.layer_norm(l_input + F.dropout(l_output,0.1))\n",
    "    \n",
    "    \n",
    "    def dot_attention(self,query, kvpairs):\n",
    "        \"\"\"\n",
    "        Scaled Dot-Product Attention\n",
    "        \"\"\"\n",
    "        \n",
    "        hidden = hidden.squeeze(0).unsqueeze(2)  # 히든 : (1,배치,차원) -> (배치,차원,1)\n",
    "        \n",
    "        batch_size = encoder_outputs.size(0) # B\n",
    "        max_len = encoder_outputs.size(1) # T\n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size*max_len,-1)) # B*T,D -> B*T,D\n",
    "        energies = energies.view(batch_size,max_len,-1) # B,T,D (배치,타임,차원)\n",
    "        \n",
    "        attn_energies = energies.bmm(hidden).transpose(1,2) # B,T,D * B,D,1 --> B,1,T \n",
    "        \n",
    "        alpha = F.softmax(attn_energies.squeeze(1)) # B,T\n",
    "        alpha = alpha.unsqueeze(1) # B,1,T\n",
    "        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D => B,1,D\n",
    "        \n",
    "        \n",
    "        return context # B,1,D\n",
    "    \n",
    "    def multihead_attention(self,something):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, input):\n",
    "       \n",
    "        embedded = self.embedding(input) # B,T,D\n",
    "        embedded = self.positional_embedding(embedded) # positional embedding\n",
    "        \n",
    "        for n in range(len(self.n_layers)):\n",
    "            output = self.multihead_attention(embedded)\n",
    "            output = self.residual(embedded,output)\n",
    "            \n",
    "            \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
