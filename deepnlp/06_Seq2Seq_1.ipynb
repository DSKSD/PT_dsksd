{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f34bc1d8648>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab;tagger=Mecab()\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 최대 길이 (10,10)으로 고정하고 PAD & Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH=10\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('../../dataset/corpus/dsksd_chat.txt').readlines()\n",
    "data = [[t.split('\\\\t')[0],t.split('\\\\t')[1][:-1]] for t in data if t !='\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SIZE = len(data) # 배치 사이즈\n",
    "DATA_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 형태소 분석\n",
    "2. 최대 길이 10보다 긴 것들 10으로 제한\n",
    "3. EOS 태그 달기\n",
    "4. 길이 10이 안되는 것들 PADDING\n",
    "5. [[Q,A]...] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t0,t1 in data:\n",
    "    token0 = tagger.morphs(t0)\n",
    "    \n",
    "    if len(token0)>=SEQ_LENGTH:\n",
    "        token0= token0[:SEQ_LENGTH-1]\n",
    "    token0.append(\"EOS\")\n",
    "\n",
    "    token1 = tagger.morphs(t1)\n",
    "    if len(token1)>=SEQ_LENGTH:\n",
    "        token1=token1[:SEQ_LENGTH-1]\n",
    "    \n",
    "    token1.append(\"EOS\")\n",
    "    while len(token0)<SEQ_LENGTH:\n",
    "        token0.append('PAD')\n",
    "    \n",
    "    while len(token1)<SEQ_LENGTH:\n",
    "        token1.append('PAD')\n",
    "    \n",
    "    train.append([token0,token1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['끝말잇기', '고', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
       " ['저', '바보', '라', '몰라요', 'ㅠㅠ', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱스 딕셔너리 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words=3\n",
    "word2index={\"SOS\":0,\"EOS\":1,\"PAD\":2}\n",
    "\n",
    "for t0,t1 in train:\n",
    "    for token in t0+t1:\n",
    "        if token not in word2index:\n",
    "            word2index[token]=n_words\n",
    "            n_words+=1\n",
    "\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to Tensor(LongTensor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 토큰을 인덱스로 바꾼 후, LongTensor로 만든 후, autograd.Variable로 wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = list(map(lambda w: to_ix[w], seq))\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "train_y=[]\n",
    "lengths=[]\n",
    "for tr in train:\n",
    "    temp = prepare_sequence(tr[0], word2index)\n",
    "    temp = temp.view(1,-1)\n",
    "    train_x.append(temp)\n",
    "\n",
    "    temp2 = prepare_sequence(tr[1],word2index)\n",
    "    temp2 = temp2.view(1,-1)\n",
    "    train_y.append(temp2)\n",
    "    \n",
    "    length = [t for t in tr[1] if t !='PAD']\n",
    "    lengths.append(len(length))\n",
    "\n",
    "inputs = torch.cat(train_x)\n",
    "targets = torch.cat(train_y)\n",
    "\n",
    "del train_x\n",
    "del train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕', '하', '세요', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,batch_first=True)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, input.size(0), self.hidden_size)) \n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN (\n",
      "  (embedding): Embedding(453, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(len(word2index), 10, 2)\n",
    "print(encoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 10]) torch.Size([2, 2, 10])\n"
     ]
    }
   ],
   "source": [
    "out, hidden = encoder_test(inputs[:2].view(2,-1))\n",
    "print(out.size(), hidden.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder without Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 모든 타입스텝마다 Context Vector를 결합확률로 같이 집어 넣어서 디코딩에 사용한다. <br>\n",
    "즉 매 스텝마다 3가지의 인풋을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_t = g(h_{t−1}, c, y_{t−1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1406.1078.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        \n",
    "        # Define the layers\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        #self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # 요 부분에서 y_{t-1}과 c를 concat해서 넣어준다..!\n",
    "        # 이게 논문에서 제시하는 방법과는 조금 다른듯..\n",
    "        # gru의 내부까지 컨트롤 할 방법이 없으니 (직접 짜지 않는 이상)\n",
    "        self.gru = nn.GRU(self.hidden_size*2, self.hidden_size, self.n_layers,batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "        \n",
    "    def forward(self, input,context,lengths,seq_length,training=True):\n",
    "        \n",
    "        # Get the embedding of the current input word\n",
    "        embedded = self.embedding(input)\n",
    "        hidden = Variable(torch.zeros(self.n_layers, input.size(0), self.hidden_size)) \n",
    "        #embedded = self.dropout(embedded)\n",
    "        \n",
    "        decode=[]\n",
    "        # Apply GRU to the output so far\n",
    "        for i in range(seq_length):\n",
    "            \n",
    "            \n",
    "            _, hidden = self.gru(torch.cat((embedded,context),2), hidden)\n",
    "            concated = torch.cat((hidden,context.transpose(0,1)),2)\n",
    "            score = self.out(concated.squeeze(0))\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            decode.append(softmaxed)\n",
    "            _,input = torch.max(softmaxed,1)\n",
    "            embedded = self.embedding(input)\n",
    "            #embedded = self.dropout(embedded)\n",
    "        \n",
    "        # if training:\n",
    "        # TODO 패딩이 아닌 진짜 length만 cost 계산하기...\n",
    "            \n",
    "        # 요고 주의! time-step을 column-wise concat한 후, reshape!!\n",
    "        scores = torch.cat(decode,1)\n",
    "        return scores.view(input.size(0)*seq_length,-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레이닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "LEARNING_RATE=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder =  EncoderRNN(len(word2index), HIDDEN_SIZE, 2)\n",
    "decoder = DecoderRNN(HIDDEN_SIZE,len(word2index))\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "enc_optim= optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Variable(torch.LongTensor([[SOS_token]*DATA_SIZE])).transpose(1,0)\n",
    "outputs,context = encoder(inputs)\n",
    "\n",
    "score = decoder(decoder_input,context[-1].view(DATA_SIZE,1,-1),lengths,SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss : 6.119385719299316\n",
      "[100] loss : 1.5012859106063843\n",
      "[200] loss : 0.5430554151535034\n",
      "[300] loss : 0.15224875509738922\n",
      "[400] loss : 0.060109205543994904\n",
      "[500] loss : 0.04042838513851166\n",
      "[600] loss : 0.031136948615312576\n",
      "[700] loss : 0.023928051814436913\n",
      "[800] loss : 0.021703246980905533\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]*DATA_SIZE])).transpose(1,0)\n",
    "    _,context = encoder(inputs)\n",
    "\n",
    "    score = decoder(decoder_input,context[-1].view(DATA_SIZE,1,-1),lengths,SEQ_LENGTH)\n",
    "    loss=loss_function(score,targets.view(-1))\n",
    "    losses.append(loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), 5.0)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), 5.0)\n",
    "    \n",
    "    enc_optim.step()\n",
    "    dec_optim.step()\n",
    "    \n",
    "    if epoch % 100==0:\n",
    "        print(\"[{epoch}] loss : {loss}\".format(epoch=epoch,loss=loss.data.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  야야\n",
      "\n",
      "A:  네 안녕 하 세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = random.choice(range(DATA_SIZE))\n",
    "input_ = train[index][0]\n",
    "target = train[index][1]\n",
    "print('Q: ', ' '.join([i for i in input_ if i !='PAD' and i != 'EOS'])+'\\n')\n",
    "\n",
    "\n",
    "decoder_input = Variable(torch.LongTensor([[SOS_token]])).transpose(1,0)\n",
    "_,context = encoder(inputs[index].view(1,-1))\n",
    "\n",
    "score = decoder(decoder_input,context[-1].view(1,1,-1),lengths,SEQ_LENGTH)\n",
    "\n",
    "v,i = torch.max(score,1)\n",
    "\n",
    "decoded=[]\n",
    "for t in range(i.size()[0]):\n",
    "    decoded.append(index2word[i.data.numpy()[t][0]])\n",
    "\n",
    "print('A: ', ' '.join([i for i in decoded if i !='PAD' and i != 'EOS'])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
