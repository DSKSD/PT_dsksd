{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://arxiv.org/abs/1408.5882\n",
    "* http://docs.likejazz.com/cnn-text-classification-tf/\n",
    "* https://github.com/Shawn1993/cnn-text-classification-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5ac00f7600>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab;tagger=Mecab()\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import PackedSequence,pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initially keep the\n",
    "word vectors static and learn only the other parameters\n",
    "of the model <br>\n",
    " Learning task-specific vectors through\n",
    "fine-tuning results in further improvements<br>\n",
    " We\n",
    "finally describe a simple modification to the architecture\n",
    "to allow for the use of both pre-trained and\n",
    "task-specific vectors by having multiple channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_num,embed_dim,class_num,kernel_num,kernel_sizes,dropout):\n",
    "        super(CNN_Text,self).__init__()\n",
    "        #self.args = args\n",
    "        \n",
    "        V = embed_num # num of vocab\n",
    "        D = embed_dim # dimenstion of word vector\n",
    "        C = class_num # num of class\n",
    "        Ci = 1\n",
    "        Co = kernel_num # 100\n",
    "        Ks = kernel_sizes # [3,4,5]\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        #self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        \n",
    "        # kernal_size = (K,D) : D는 단어 벡터 길이라 픽스, K 사이즈만큼 슬라이딩, 스트라이드는 1\n",
    "        \n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3) #(N,Co,W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x,train=True):\n",
    "        x = self.embed(x) # (N,W,D)\n",
    "        \n",
    "        #if self.args.static:\n",
    "        #    x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1) # (N,Ci,W,D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] #[(N,Co,W), ...]*len(Ks)\n",
    "\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] #[(N,Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        if train:\n",
    "            x = self.dropout(x) # (N,len(Ks)*Co)\n",
    "        logit = self.fc1(x) # (N,C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from konlpy.tag import Mecab\n",
    "tagger = Mecab()\n",
    "\n",
    "stopwords=['dummy']\n",
    "# Helper functions to make the code more readable.\n",
    "def prepare_sequence(seq, word_to_ix):\n",
    "    idxs=[]\n",
    "    for s in seq:\n",
    "        \n",
    "        if s.isdigit():\n",
    "            idxs.append(word_to_ix['NUM'])\n",
    "            continue\n",
    "        try:    \n",
    "            if s not in stopwords:\n",
    "                idxs.append(word_to_ix[s])\n",
    "            else:\n",
    "                idxs.append(word_to_ix['UNK'])\n",
    "        except:\n",
    "            idxs.append(word_to_ix['UNK'])\n",
    "    \n",
    "    #idxs = list(map(lambda w: to_ix[w], seq))\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    tensor = Variable(tensor)\n",
    "    if USE_CUDA: tensor = tensor.cuda()\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = json.load(open('../../dataset/corpus/domain_dump_07_10_17.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = zip(*train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_ix={'PAD':0,'UNK':1,'NUM':2}\n",
    "\n",
    "for x in X:\n",
    "    tokens = tagger.morphs(x)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token.isnumeric():\n",
    "            token = 'NUM'\n",
    "        if token not in word_to_ix:\n",
    "            word_to_ix[token]=len(word_to_ix)\n",
    "\n",
    "ix_to_word = {v:k for k,v in word_to_ix.items()}\n",
    "\n",
    "target_to_ix={}\n",
    "\n",
    "for y_ in y:\n",
    "    if y_ not in target_to_ix:\n",
    "        target_to_ix[y_]=len(target_to_ix)\n",
    "        \n",
    "ix_to_target = {v:k for k,v in target_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_p = []\n",
    "except_index=[]\n",
    "for x in X:\n",
    "    tokens = tagger.morphs(x)\n",
    "    while len(tokens) < 5:\n",
    "        tokens.append('PAD')\n",
    "        \n",
    "    tokens = ['NUM' if token.isnumeric() else token for token in tokens]\n",
    "    X_p.append(prepare_sequence(tokens,word_to_ix).view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = CNN_Text(len(word_to_ix),30,len(target_to_ix),30,[3,4,5],0.8)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = list(zip(X_p,list(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.446259617805481\n",
      "10 1.254598617553711\n",
      "20 1.2565611600875854\n",
      "30 1.1359226703643799\n",
      "40 2.089221239089966\n",
      "50 2.5133934020996094\n",
      "60 0.26536357402801514\n",
      "70 0.24461354315280914\n",
      "80 0.25541332364082336\n",
      "90 1.168743371963501\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    losses=[]\n",
    "    for i,(sent,target) in enumerate(train):\n",
    "        \n",
    "        pred = model(sent)\n",
    "        target = Variable(torch.LongTensor([target_to_ix[target]]))\n",
    "        loss = loss_function(pred,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    if step % 10==0:\n",
    "        print(step,np.mean(losses).data.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = [\"다음주 부산 날씨 머야?\",\n",
    "            \"오늘 저녁에 집 앞에서 미팅\",\n",
    "            \"이거 어떻게 하는거야?\",\n",
    "            \"꽃다발 배달하고 싶어!\",\n",
    "            \"장미 배달 돼? 빨간색으로\",\n",
    "            \"이거 너무하네 진짜\",\n",
    "            \"ㅇㅇㅇㅇ내일 비 와??\",\n",
    "            \"이번 주말에 서울에 비 안오지?\",\n",
    "            \"하이루 내일 뭐하니\",\n",
    "            \"조화 보내고 싶은데 어케해\",\n",
    "            \"ㅋㅋㅋ이메일 보내고 싶어!\",\n",
    "            \"어쭈구리?ㅋㅋ 혼난다ㅡㅡ\",\n",
    "           \"됐고ㅡㅡ 내일 날씨나 알려줘\",\n",
    "           \"오늘 일정이 어케됭?ㅋ\",\n",
    "           \"흐아.. 진자 못맞추는구나 보내고\",\n",
    "            \"어키,, 알겠으 정말 바보구나 싶어\",\n",
    "           \"헐 날씨 넘나 좋은것\",\n",
    "            \"문봇의 문이 뭐야?\",\n",
    "            \"너 꽃배달 업체가 어디야?\",\n",
    "            \"꽃만 들어 있으면 이걸로 판단하는거냐\",\n",
    "            \"ㅋㅋㅋ너네 패턴 다 파악함\",\n",
    "            \"날씨도 좋은데 꽃이나 보낼래\",\n",
    "            \"꽃은 안보내도 되고, 날씨나 알려줘\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음주 부산 날씨 머야? WEATHER\n",
      "오늘 저녁에 집 앞에서 미팅 SCHEDULE\n",
      "이거 어떻게 하는거야? OTHER\n",
      "꽃다발 배달하고 싶어! FLOWER\n",
      "장미 배달 돼? 빨간색으로 FLOWER\n",
      "이거 너무하네 진짜 OTHER\n",
      "ㅇㅇㅇㅇ내일 비 와?? WEATHER\n",
      "이번 주말에 서울에 비 안오지? OTHER\n",
      "하이루 내일 뭐하니 OTHER\n",
      "조화 보내고 싶은데 어케해 FLOWER\n",
      "ㅋㅋㅋ이메일 보내고 싶어! FLOWER\n",
      "어쭈구리?ㅋㅋ 혼난다ㅡㅡ OTHER\n",
      "됐고ㅡㅡ 내일 날씨나 알려줘 OTHER\n",
      "오늘 일정이 어케됭?ㅋ OTHER\n",
      "흐아.. 진자 못맞추는구나 보내고 FLOWER\n",
      "어키,, 알겠으 정말 바보구나 싶어 FLOWER\n",
      "헐 날씨 넘나 좋은것 OTHER\n",
      "문봇의 문이 뭐야? OTHER\n",
      "너 꽃배달 업체가 어디야? FLOWER\n",
      "꽃만 들어 있으면 이걸로 판단하는거냐 FLOWER\n",
      "ㅋㅋㅋ너네 패턴 다 파악함 OTHER\n",
      "날씨도 좋은데 꽃이나 보낼래 FLOWER\n",
      "꽃은 안보내도 되고, 날씨나 알려줘 FLOWER\n"
     ]
    }
   ],
   "source": [
    "for t in test:\n",
    "    tokens = tagger.morphs(t)\n",
    "    input = prepare_sequence(tokens,word_to_ix)\n",
    "    pred = model(input.view(1,-1),False)\n",
    "    v,i = torch.max(pred,1)\n",
    "    result = ix_to_target[i.data.tolist()[0][0]]\n",
    "    \n",
    "    print(t,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
