{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://arxiv.org/pdf/1312.6114.pdf\n",
    "* http://norman3.github.io/prml/docs/chapter10/0.html\n",
    "* http://nolsigan.com/blog/what-is-variational-autoencoder/\n",
    "* http://jaejunyoo.blogspot.com/2017/04/auto-encoding-variational-bayes-vae-2.html\n",
    "* https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/variational_auto_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From a neural network perspective, the only difference between the VAE and the Auto-Encoder(AE) is that the latent vector z in VAE is stochastically sampled. This solves the problem that the AE learns identity mapping and can not have meaningful representations in latent space. In fact, the VAE uses reparameterization trick to enable back propagation without sampling z directly from the mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "hidden_size = 400 # undercomplete !\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='../../dataset/mnist', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='../../dataset/mnist', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim*2))  # 2 for mean and variance.\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def reparametrize(self, mu, log_var):\n",
    "        \"\"\"\"z = mean + eps * sigma where eps is sampled from N(0, 1).\"\"\"\n",
    "        eps = to_var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + eps * torch.exp(log_var/2)    # 2 for convert var to std\n",
    "        return z\n",
    "                     \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim=1)  # mean and log variance.\n",
    "        z = self.reparametrize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELBO LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "Recon = nn.BCELoss() \n",
    "num_epochs=50\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50], Step: [100/600], ELBO: 17396.2520 , Recon: 16145.3330, KLD: 1250.9198\n",
      "Epoch: [1/50], Step: [200/600], ELBO: 14470.4492 , Recon: 12754.6846, KLD: 1715.7644\n",
      "Epoch: [1/50], Step: [300/600], ELBO: 14041.0010 , Recon: 12064.6260, KLD: 1976.3746\n",
      "Epoch: [1/50], Step: [400/600], ELBO: 12873.3291 , Recon: 10723.1963, KLD: 2150.1331\n",
      "Epoch: [1/50], Step: [500/600], ELBO: 12459.9023 , Recon: 10079.8564, KLD: 2380.0464\n",
      "Epoch: [1/50], Step: [600/600], ELBO: 11707.6172 , Recon: 9453.5723, KLD: 2254.0449\n",
      "Epoch: [2/50], Step: [100/600], ELBO: 11697.1182 , Recon: 9440.1582, KLD: 2256.9600\n",
      "Epoch: [2/50], Step: [200/600], ELBO: 11548.6602 , Recon: 9198.4561, KLD: 2350.2036\n",
      "Epoch: [2/50], Step: [300/600], ELBO: 11794.0781 , Recon: 9407.4805, KLD: 2386.5981\n",
      "Epoch: [2/50], Step: [400/600], ELBO: 11914.7412 , Recon: 9463.6738, KLD: 2451.0676\n",
      "Epoch: [2/50], Step: [500/600], ELBO: 11367.3057 , Recon: 8941.1025, KLD: 2426.2029\n",
      "Epoch: [2/50], Step: [600/600], ELBO: 11506.7324 , Recon: 9076.8682, KLD: 2429.8643\n",
      "Epoch: [3/50], Step: [100/600], ELBO: 11294.5801 , Recon: 8877.5342, KLD: 2417.0459\n",
      "Epoch: [3/50], Step: [200/600], ELBO: 11470.2822 , Recon: 8966.9814, KLD: 2503.3008\n",
      "Epoch: [3/50], Step: [300/600], ELBO: 11323.6035 , Recon: 8824.5703, KLD: 2499.0334\n",
      "Epoch: [3/50], Step: [400/600], ELBO: 11210.7520 , Recon: 8769.2549, KLD: 2441.4968\n",
      "Epoch: [3/50], Step: [500/600], ELBO: 11175.7246 , Recon: 8711.4834, KLD: 2464.2412\n",
      "Epoch: [3/50], Step: [600/600], ELBO: 11045.9756 , Recon: 8583.5557, KLD: 2462.4197\n",
      "Epoch: [4/50], Step: [100/600], ELBO: 10559.7002 , Recon: 8145.6191, KLD: 2414.0813\n",
      "Epoch: [4/50], Step: [200/600], ELBO: 11041.2617 , Recon: 8609.2959, KLD: 2431.9653\n",
      "Epoch: [4/50], Step: [300/600], ELBO: 10969.7041 , Recon: 8511.0332, KLD: 2458.6707\n",
      "Epoch: [4/50], Step: [400/600], ELBO: 10874.8730 , Recon: 8301.9736, KLD: 2572.8997\n",
      "Epoch: [4/50], Step: [500/600], ELBO: 10607.2246 , Recon: 8169.6699, KLD: 2437.5549\n",
      "Epoch: [4/50], Step: [600/600], ELBO: 11107.0576 , Recon: 8594.2354, KLD: 2512.8223\n",
      "Epoch: [5/50], Step: [100/600], ELBO: 10862.3340 , Recon: 8370.9668, KLD: 2491.3674\n",
      "Epoch: [5/50], Step: [200/600], ELBO: 11105.9961 , Recon: 8626.7070, KLD: 2479.2886\n",
      "Epoch: [5/50], Step: [300/600], ELBO: 10541.1152 , Recon: 8072.6650, KLD: 2468.4500\n",
      "Epoch: [5/50], Step: [400/600], ELBO: 11120.3867 , Recon: 8663.0195, KLD: 2457.3667\n",
      "Epoch: [5/50], Step: [500/600], ELBO: 10250.5020 , Recon: 7778.2910, KLD: 2472.2114\n",
      "Epoch: [5/50], Step: [600/600], ELBO: 10699.0596 , Recon: 8175.5239, KLD: 2523.5356\n",
      "Epoch: [6/50], Step: [100/600], ELBO: 10921.3145 , Recon: 8342.3076, KLD: 2579.0071\n",
      "Epoch: [6/50], Step: [200/600], ELBO: 10916.3730 , Recon: 8400.2480, KLD: 2516.1250\n",
      "Epoch: [6/50], Step: [300/600], ELBO: 10174.6924 , Recon: 7756.7866, KLD: 2417.9060\n",
      "Epoch: [6/50], Step: [400/600], ELBO: 10082.6602 , Recon: 7647.2734, KLD: 2435.3865\n",
      "Epoch: [6/50], Step: [500/600], ELBO: 11143.0078 , Recon: 8602.1924, KLD: 2540.8149\n",
      "Epoch: [6/50], Step: [600/600], ELBO: 10597.2227 , Recon: 8099.2822, KLD: 2497.9402\n",
      "Epoch: [7/50], Step: [100/600], ELBO: 10420.2451 , Recon: 7961.6880, KLD: 2458.5574\n",
      "Epoch: [7/50], Step: [200/600], ELBO: 10938.8164 , Recon: 8346.2285, KLD: 2592.5874\n",
      "Epoch: [7/50], Step: [300/600], ELBO: 10642.8154 , Recon: 8152.7686, KLD: 2490.0466\n",
      "Epoch: [7/50], Step: [400/600], ELBO: 10609.9551 , Recon: 8129.6611, KLD: 2480.2935\n",
      "Epoch: [7/50], Step: [500/600], ELBO: 10756.4277 , Recon: 8264.4023, KLD: 2492.0256\n",
      "Epoch: [7/50], Step: [600/600], ELBO: 10620.4707 , Recon: 8081.9463, KLD: 2538.5247\n",
      "Epoch: [8/50], Step: [100/600], ELBO: 10574.9678 , Recon: 8079.9521, KLD: 2495.0156\n",
      "Epoch: [8/50], Step: [200/600], ELBO: 10794.5918 , Recon: 8271.6787, KLD: 2522.9126\n",
      "Epoch: [8/50], Step: [300/600], ELBO: 10276.8730 , Recon: 7723.3188, KLD: 2553.5542\n",
      "Epoch: [8/50], Step: [400/600], ELBO: 10644.9102 , Recon: 8091.0820, KLD: 2553.8284\n",
      "Epoch: [8/50], Step: [500/600], ELBO: 10937.6699 , Recon: 8412.8574, KLD: 2524.8125\n",
      "Epoch: [8/50], Step: [600/600], ELBO: 10551.9102 , Recon: 8056.8140, KLD: 2495.0957\n",
      "Epoch: [9/50], Step: [100/600], ELBO: 10720.8955 , Recon: 8227.1445, KLD: 2493.7507\n",
      "Epoch: [9/50], Step: [200/600], ELBO: 10102.3457 , Recon: 7618.5210, KLD: 2483.8245\n",
      "Epoch: [9/50], Step: [300/600], ELBO: 10431.9912 , Recon: 8011.4189, KLD: 2420.5723\n",
      "Epoch: [9/50], Step: [400/600], ELBO: 10780.1006 , Recon: 8220.8076, KLD: 2559.2930\n",
      "Epoch: [9/50], Step: [500/600], ELBO: 10686.1650 , Recon: 8219.5098, KLD: 2466.6555\n",
      "Epoch: [9/50], Step: [600/600], ELBO: 10260.6094 , Recon: 7751.7822, KLD: 2508.8274\n",
      "Epoch: [10/50], Step: [100/600], ELBO: 10261.0381 , Recon: 7790.5342, KLD: 2470.5037\n",
      "Epoch: [10/50], Step: [200/600], ELBO: 10421.9258 , Recon: 7905.1465, KLD: 2516.7793\n",
      "Epoch: [10/50], Step: [300/600], ELBO: 10853.6465 , Recon: 8257.0000, KLD: 2596.6465\n",
      "Epoch: [10/50], Step: [400/600], ELBO: 10492.0547 , Recon: 7986.8560, KLD: 2505.1992\n",
      "Epoch: [10/50], Step: [500/600], ELBO: 10088.7031 , Recon: 7495.2661, KLD: 2593.4365\n",
      "Epoch: [10/50], Step: [600/600], ELBO: 10762.1924 , Recon: 8227.1924, KLD: 2535.0002\n",
      "Epoch: [11/50], Step: [100/600], ELBO: 10659.9219 , Recon: 8108.2368, KLD: 2551.6855\n",
      "Epoch: [11/50], Step: [200/600], ELBO: 10737.9775 , Recon: 8133.8213, KLD: 2604.1560\n",
      "Epoch: [11/50], Step: [300/600], ELBO: 10277.3838 , Recon: 7810.8262, KLD: 2466.5574\n",
      "Epoch: [11/50], Step: [400/600], ELBO: 10472.1299 , Recon: 7971.5132, KLD: 2500.6169\n",
      "Epoch: [11/50], Step: [500/600], ELBO: 10571.6992 , Recon: 8040.7700, KLD: 2530.9294\n",
      "Epoch: [11/50], Step: [600/600], ELBO: 10735.5010 , Recon: 8192.5410, KLD: 2542.9597\n",
      "Epoch: [12/50], Step: [100/600], ELBO: 10538.7002 , Recon: 8008.9922, KLD: 2529.7080\n",
      "Epoch: [12/50], Step: [200/600], ELBO: 10286.3662 , Recon: 7835.5215, KLD: 2450.8445\n",
      "Epoch: [12/50], Step: [300/600], ELBO: 10272.1045 , Recon: 7776.1357, KLD: 2495.9685\n",
      "Epoch: [12/50], Step: [400/600], ELBO: 10393.3828 , Recon: 7890.7935, KLD: 2502.5894\n",
      "Epoch: [12/50], Step: [500/600], ELBO: 10583.3262 , Recon: 8003.3716, KLD: 2579.9551\n",
      "Epoch: [12/50], Step: [600/600], ELBO: 10116.3555 , Recon: 7729.4575, KLD: 2386.8984\n",
      "Epoch: [13/50], Step: [100/600], ELBO: 10977.5977 , Recon: 8342.4590, KLD: 2635.1389\n",
      "Epoch: [13/50], Step: [200/600], ELBO: 10690.8438 , Recon: 8149.1548, KLD: 2541.6885\n",
      "Epoch: [13/50], Step: [300/600], ELBO: 10415.4863 , Recon: 7910.4385, KLD: 2505.0474\n",
      "Epoch: [13/50], Step: [400/600], ELBO: 10393.1895 , Recon: 7810.8394, KLD: 2582.3501\n",
      "Epoch: [13/50], Step: [500/600], ELBO: 10190.1895 , Recon: 7659.7314, KLD: 2530.4583\n",
      "Epoch: [13/50], Step: [600/600], ELBO: 10316.8779 , Recon: 7793.8604, KLD: 2523.0176\n",
      "Epoch: [14/50], Step: [100/600], ELBO: 10542.6338 , Recon: 7993.0137, KLD: 2549.6199\n",
      "Epoch: [14/50], Step: [200/600], ELBO: 10619.6377 , Recon: 8025.2676, KLD: 2594.3701\n",
      "Epoch: [14/50], Step: [300/600], ELBO: 10697.0205 , Recon: 8099.8276, KLD: 2597.1929\n",
      "Epoch: [14/50], Step: [400/600], ELBO: 9980.0176 , Recon: 7471.6943, KLD: 2508.3235\n",
      "Epoch: [14/50], Step: [500/600], ELBO: 10230.7910 , Recon: 7754.0645, KLD: 2476.7263\n",
      "Epoch: [14/50], Step: [600/600], ELBO: 10909.7568 , Recon: 8276.3135, KLD: 2633.4434\n",
      "Epoch: [15/50], Step: [100/600], ELBO: 10458.4707 , Recon: 7917.9976, KLD: 2540.4731\n",
      "Epoch: [15/50], Step: [200/600], ELBO: 10440.5703 , Recon: 7869.0493, KLD: 2571.5210\n",
      "Epoch: [15/50], Step: [300/600], ELBO: 10245.3965 , Recon: 7738.4492, KLD: 2506.9478\n",
      "Epoch: [15/50], Step: [400/600], ELBO: 10750.8623 , Recon: 8082.2803, KLD: 2668.5820\n",
      "Epoch: [15/50], Step: [500/600], ELBO: 10762.8848 , Recon: 8152.8042, KLD: 2610.0803\n",
      "Epoch: [15/50], Step: [600/600], ELBO: 10592.1230 , Recon: 7956.3691, KLD: 2635.7542\n",
      "Epoch: [16/50], Step: [100/600], ELBO: 10734.4609 , Recon: 8168.7915, KLD: 2565.6694\n",
      "Epoch: [16/50], Step: [200/600], ELBO: 10087.2520 , Recon: 7593.6191, KLD: 2493.6331\n",
      "Epoch: [16/50], Step: [300/600], ELBO: 10528.0967 , Recon: 7930.9922, KLD: 2597.1042\n",
      "Epoch: [16/50], Step: [400/600], ELBO: 10385.9209 , Recon: 7869.5576, KLD: 2516.3630\n",
      "Epoch: [16/50], Step: [500/600], ELBO: 10846.8232 , Recon: 8248.4912, KLD: 2598.3318\n",
      "Epoch: [16/50], Step: [600/600], ELBO: 10874.8594 , Recon: 8206.9395, KLD: 2667.9197\n",
      "Epoch: [17/50], Step: [100/600], ELBO: 10556.6689 , Recon: 7957.9141, KLD: 2598.7551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17/50], Step: [200/600], ELBO: 10732.2500 , Recon: 8091.0879, KLD: 2641.1626\n",
      "Epoch: [17/50], Step: [300/600], ELBO: 10161.9219 , Recon: 7602.9297, KLD: 2558.9917\n",
      "Epoch: [17/50], Step: [400/600], ELBO: 10627.1660 , Recon: 8006.0757, KLD: 2621.0898\n",
      "Epoch: [17/50], Step: [500/600], ELBO: 10710.2363 , Recon: 8110.3916, KLD: 2599.8442\n",
      "Epoch: [17/50], Step: [600/600], ELBO: 10363.4990 , Recon: 7813.9565, KLD: 2549.5427\n",
      "Epoch: [18/50], Step: [100/600], ELBO: 10201.1875 , Recon: 7616.2012, KLD: 2584.9863\n",
      "Epoch: [18/50], Step: [200/600], ELBO: 10362.8447 , Recon: 7728.3706, KLD: 2634.4744\n",
      "Epoch: [18/50], Step: [300/600], ELBO: 10422.5098 , Recon: 7898.1899, KLD: 2524.3201\n",
      "Epoch: [18/50], Step: [400/600], ELBO: 10374.5039 , Recon: 7767.0112, KLD: 2607.4922\n",
      "Epoch: [18/50], Step: [500/600], ELBO: 10153.5742 , Recon: 7664.1978, KLD: 2489.3762\n",
      "Epoch: [18/50], Step: [600/600], ELBO: 10599.0020 , Recon: 7980.7695, KLD: 2618.2322\n",
      "Epoch: [19/50], Step: [100/600], ELBO: 9912.6299 , Recon: 7404.7168, KLD: 2507.9131\n",
      "Epoch: [19/50], Step: [200/600], ELBO: 10349.2109 , Recon: 7872.0239, KLD: 2477.1875\n",
      "Epoch: [19/50], Step: [300/600], ELBO: 10745.4180 , Recon: 8155.6655, KLD: 2589.7522\n",
      "Epoch: [19/50], Step: [400/600], ELBO: 10881.1992 , Recon: 8304.6523, KLD: 2576.5474\n",
      "Epoch: [19/50], Step: [500/600], ELBO: 10050.5986 , Recon: 7602.2920, KLD: 2448.3064\n",
      "Epoch: [19/50], Step: [600/600], ELBO: 10038.0449 , Recon: 7599.0723, KLD: 2438.9729\n",
      "Epoch: [20/50], Step: [100/600], ELBO: 11159.9326 , Recon: 8566.4756, KLD: 2593.4570\n",
      "Epoch: [20/50], Step: [200/600], ELBO: 10898.6729 , Recon: 8322.8193, KLD: 2575.8538\n",
      "Epoch: [20/50], Step: [300/600], ELBO: 10669.1133 , Recon: 8074.8872, KLD: 2594.2256\n",
      "Epoch: [20/50], Step: [400/600], ELBO: 10411.7734 , Recon: 7910.0337, KLD: 2501.7402\n",
      "Epoch: [20/50], Step: [500/600], ELBO: 10578.3613 , Recon: 8000.7651, KLD: 2577.5959\n",
      "Epoch: [20/50], Step: [600/600], ELBO: 9637.8799 , Recon: 7225.3862, KLD: 2412.4934\n",
      "Epoch: [21/50], Step: [100/600], ELBO: 10074.8281 , Recon: 7556.8931, KLD: 2517.9355\n",
      "Epoch: [21/50], Step: [200/600], ELBO: 10217.6611 , Recon: 7730.0093, KLD: 2487.6519\n",
      "Epoch: [21/50], Step: [300/600], ELBO: 10422.0039 , Recon: 7847.7583, KLD: 2574.2454\n",
      "Epoch: [21/50], Step: [400/600], ELBO: 10446.1377 , Recon: 7887.9951, KLD: 2558.1426\n",
      "Epoch: [21/50], Step: [500/600], ELBO: 10170.3457 , Recon: 7714.7803, KLD: 2455.5654\n",
      "Epoch: [21/50], Step: [600/600], ELBO: 10391.2812 , Recon: 7860.9976, KLD: 2530.2839\n",
      "Epoch: [22/50], Step: [100/600], ELBO: 10664.3838 , Recon: 8099.3677, KLD: 2565.0159\n",
      "Epoch: [22/50], Step: [200/600], ELBO: 10279.8203 , Recon: 7721.9175, KLD: 2557.9031\n",
      "Epoch: [22/50], Step: [300/600], ELBO: 10879.2217 , Recon: 8266.5518, KLD: 2612.6702\n",
      "Epoch: [22/50], Step: [400/600], ELBO: 10407.8887 , Recon: 7892.6504, KLD: 2515.2388\n",
      "Epoch: [22/50], Step: [500/600], ELBO: 9977.8750 , Recon: 7463.3442, KLD: 2514.5312\n",
      "Epoch: [22/50], Step: [600/600], ELBO: 10462.4346 , Recon: 7965.8940, KLD: 2496.5403\n",
      "Epoch: [23/50], Step: [100/600], ELBO: 10848.8750 , Recon: 8319.8418, KLD: 2529.0327\n",
      "Epoch: [23/50], Step: [200/600], ELBO: 10292.5918 , Recon: 7827.8687, KLD: 2464.7231\n",
      "Epoch: [23/50], Step: [300/600], ELBO: 10464.9775 , Recon: 7888.4155, KLD: 2576.5620\n",
      "Epoch: [23/50], Step: [400/600], ELBO: 10342.5352 , Recon: 7784.9395, KLD: 2557.5962\n",
      "Epoch: [23/50], Step: [500/600], ELBO: 10294.7744 , Recon: 7791.4707, KLD: 2503.3035\n",
      "Epoch: [23/50], Step: [600/600], ELBO: 10152.4785 , Recon: 7642.6294, KLD: 2509.8489\n",
      "Epoch: [24/50], Step: [100/600], ELBO: 10394.5322 , Recon: 7740.4971, KLD: 2654.0354\n",
      "Epoch: [24/50], Step: [200/600], ELBO: 10301.7900 , Recon: 7754.8486, KLD: 2546.9417\n",
      "Epoch: [24/50], Step: [300/600], ELBO: 10179.3486 , Recon: 7713.9482, KLD: 2465.4001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d2817a80f6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Forward + Backward + Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# q(z|x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dsksd/.local/lib/python3.5/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        normal = Variable(torch.randn([batch_size,hidden_size])) \n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        recon,mu, log_var = vae(images) # q(z|x)\n",
    "        recon_loss = F.binary_cross_entropy(recon, images, size_average=False)\n",
    "        kld_loss = torch.sum(0.5 * (mu**2 + torch.exp(log_var) - log_var -1))\n",
    "        \n",
    "        ELBO = recon_loss+kld_loss\n",
    "        \n",
    "        ELBO.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], ELBO: %.4f , Recon: %.4f, KLD: %.4F' \n",
    "                   % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, ELBO.data[0],recon_loss.data[0],kld_loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEFCAYAAADjfVLrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f473024a2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal = Variable(torch.randn([1,20])) \n",
    "recon = vae.sample(normal)\n",
    "\n",
    "plt.matshow(np.reshape(recon.data.numpy(), (28, 28)), cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"[\" + str(epoch) + \"] Generated Image\\n\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
