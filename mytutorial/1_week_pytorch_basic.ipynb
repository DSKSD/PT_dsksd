{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fef89175930>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://pytorch.org/docs/master/\n",
    "* https://github.com/rguthrie3/DeepLearningForNLPInPytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is a Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서와 옵티마이저, 뉴럴넷 등 GPU 연산에 최적화된 모듈을 이용하여 빠르게 <strong>딥러닝 모델을 구현할 수 있는 프레임워크</strong> <br>\n",
    "Facebook이 밀고 있던 lua 기반의 torch를 python 버전으로 포팅함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is difference between Pytorch and Tensorflow? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b\n",
    "* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf\n",
    "* https://devblogs.nvidia.com/parallelforall/recursive-neural-networks-pytorch/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Why Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pythonic \n",
    "* Easy debugging\n",
    "* Intuitive => Easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1> Pytorch Basic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor\n",
    "* Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 가장 기본 단위는 Tensor이다. 디폴트 Tensor는 FloatTensor이고, LongTensor, ByteTensor, 등 여러 종류가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텐서 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  2\n",
      "  3  4\n",
      "\n",
      "(1 ,.,.) = \n",
      "  5  6\n",
      "  7  8\n",
      "[torch.FloatTensor of size 2x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V_data = [1., 2., 3.] # 벡터\n",
    "V = torch.Tensor(V_data) # 파이썬의 리스트를 바로 랩핑할 수 있다.\n",
    "print(V)\n",
    "\n",
    "M_data = [[1., 2., 3.], [4., 5., 6]] # 매트릭스\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = [[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "          [[5.,6.], [7.,8.]]]\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "numpy 객체도 막 가져올 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  2\n",
      "  3  4\n",
      "\n",
      "(1 ,.,.) = \n",
      "  5  6\n",
      "  7  8\n",
      "[torch.FloatTensor of size 2x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V_data = np.array([1.,2.,3.])# 벡터\n",
    "V = torch.Tensor(V_data) # 파이썬의 리스트를 바로 랩핑할 수 있다.\n",
    "print(V)\n",
    "\n",
    "M_data = np.array([[1., 2., 3.], [4., 5., 6]]) # 매트릭스\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = np.array([[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "          [[5.,6.], [7.,8.]]])\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      " -2.9718  1.7070 -0.4305 -2.2820  0.5237\n",
      "  0.0004 -1.2039  3.5283  0.4434  0.5848\n",
      "  0.8407  0.5510  0.3863  0.9124 -0.8410\n",
      "  1.2282 -1.8661  1.4146 -1.8781 -0.4674\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.7576  0.4215 -0.4827 -1.1198  0.3056\n",
      "  1.0386  0.5206 -0.5006  1.2182  0.2117\n",
      " -1.0613 -1.9441 -0.9596  0.5489 -0.9901\n",
      " -0.3826  1.5037  1.8267  0.5561  1.6445\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.4973 -1.5067  1.7661 -0.3569 -0.1713\n",
      "  0.4068 -0.4284 -1.1299  1.4274 -1.4027\n",
      "  1.4825 -1.1559  1.6190  0.9581  0.7747\n",
      "  0.1940  0.1687  0.3061  1.0743 -1.0327\n",
      "[torch.FloatTensor of size 3x4x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3, 4, 5)) # 3x4x5 텐서를 랜덤으로 초기화하기\n",
    "print(x) # FloatTensor가 디폴트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-2.9718  1.7070 -0.4305 -2.2820  0.5237\n",
       " 0.0004 -1.2039  3.5283  0.4434  0.5848\n",
       " 0.8407  0.5510  0.3863  0.9124 -0.8410\n",
       " 1.2282 -1.8661  1.4146 -1.8781 -0.4674\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # indexing도 직관적이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-2.9718\n",
       " 1.7070\n",
       "-0.4305\n",
       "-2.2820\n",
       " 0.5237\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9718289375305176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텐서 연산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "y = torch.Tensor([ 4., 5., 6. ])\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞으로 자주 쓰게 될 연산 <strong>cat</strong> => concat : 두 텐서를 연결한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0930  0.7769 -1.3128  0.7099  0.9944\n",
      "-0.2694 -0.6491 -0.1373 -0.2954 -0.7725\n",
      "-0.2215  0.5074 -0.6794 -1.6115  0.5230\n",
      "-0.8890  0.2620  0.0302  0.0013 -1.3987\n",
      " 1.4666 -0.1028 -0.0097 -0.8420 -0.2067\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 1.0672  0.1732 -0.6873  0.3620  0.3776 -0.2443 -0.5850  2.0812\n",
      " 0.3111  0.2358 -1.0658 -0.1186  0.4903  0.8349  0.8894  0.4148\n",
      "[torch.FloatTensor of size 2x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By default, it concatenates along the first axis (concatenates rows)\n",
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 =torch.cat([x_1, y_1]) # 디폴트는 첫번째 차원 기준으로 콘캣 (0)\n",
    "print(z_1)\n",
    "\n",
    "# Concatenate columns:\n",
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "z_2 = torch.cat([x_2, y_2], 1) # 두번째 인자로 콘캣할 차원축을 선택할 수 있다.\n",
    "print(z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞으로 자주 쓰게 될 연산 <strong>view</strong> => reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.0507 -0.9644 -2.0111  0.5245\n",
      "  2.1332 -0.0822  0.8388 -1.3233\n",
      "  0.0701  1.2200  0.4251 -1.2328\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.6195  1.5133  1.9954 -0.6585\n",
      " -0.4139 -0.2250 -0.6890  0.9882\n",
      "  0.7404 -2.0990  1.2582 -0.3990\n",
      "[torch.FloatTensor of size 2x3x4]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.0507 -0.9644 -2.0111  0.5245  2.1332 -0.0822  0.8388 -1.3233  0.0701  1.2200\n",
      "-0.6195  1.5133  1.9954 -0.6585 -0.4139 -0.2250 -0.6890  0.9882  0.7404 -2.0990\n",
      "\n",
      "Columns 10 to 11 \n",
      " 0.4251 -1.2328\n",
      " 1.2582 -0.3990\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.0507 -0.9644 -2.0111  0.5245  2.1332 -0.0822  0.8388 -1.3233  0.0701  1.2200\n",
      "-0.6195  1.5133  1.9954 -0.6585 -0.4139 -0.2250 -0.6890  0.9882  0.7404 -2.0990\n",
      "\n",
      "Columns 10 to 11 \n",
      " 0.4251 -1.2328\n",
      " 1.2582 -0.3990\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "print(x)\n",
    "print(x.view(2, 12)) # Reshape to 2 rows, 12 columns\n",
    "print(x.view(2, -1)) # Same as above.  If one of the dimensions is -1, its size can be inferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computation Graphs and Automatic Differentiation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 프레임워크의 가장 큰 장점인 자동 미분 기능을 사용하려면 텐서를 특별한 형태로 바꿔줘야 한다. (<strong>Variable</strong>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "<torch.autograd.function.AddBackward object at 0x7fef88766a98>\n"
     ]
    }
   ],
   "source": [
    "# Variables wrap tensor objects\n",
    "x = Variable( torch.Tensor([1., 2., 3]), requires_grad=True )\n",
    "# You can access the data with the .data attribute\n",
    "print(x.data)\n",
    "\n",
    "# You can also do all the same operations you did with tensors with Variables.\n",
    "y = Variable( torch.Tensor([4., 5., 6]), requires_grad=True )\n",
    "z = x + y\n",
    "print(z.data)\n",
    "\n",
    "# BUT z knows something extra.\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 21\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "<torch.autograd.function.SumBackward object at 0x7fef88766d68>\n"
     ]
    }
   ],
   "source": [
    "# Lets sum up all the entries in z\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.backward() # calling .backward() on any variable will run backprop, starting from it.\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s = \\overbrace{x_0 + y_0}^\\text{$z_0$} + \\overbrace{x_1 + y_1}^\\text{$z_1$} + \\overbrace{x_2 + y_2}^\\text{$z_2$} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial s}{\\partial x_0} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. torch Module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치는 모델을 클래스처럼 다루는데, torch.nn.Module을 상속받아서 부모 클래스를 초기화하면 된다. <br>\n",
    "선정의 된 함수 foward를 통해 모델링을 하고 나서, Variable을 인자 값으로 보내면 forward 계산을 하면서 Parameter와의 backward 연결을 알아서 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(simpleNN, self).__init__() # 부모 클래스까지 초기화\n",
    "        self.linear = nn.Linear(2,2)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        return F.sigmoid(self.linear(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snn = simpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleNN (\n",
       "  (linear): Linear (2 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear.weight', Parameter containing:\n",
      "-0.1214  0.0574\n",
      "-0.6365  0.3755\n",
      "[torch.FloatTensor of size 2x2]\n",
      ")\n",
      "('linear.bias', Parameter containing:\n",
      " 0.0508\n",
      "-0.6430\n",
      "[torch.FloatTensor of size 2]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in snn.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0952 -0.2831\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(1,2))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5418  0.4870\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = snn(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모듈 : nn.Linear (Affine Maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = Ax + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4825  0.0247  0.4566\n",
      "-0.0652 -0.7002 -0.4353\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(5, 3) # maps from R^5 to R^3, parameters A, b\n",
    "data = Variable( torch.randn(2, 5) ) # data is 2x5.  A maps from 5 to 3... can we map \"data\" under A?\n",
    "print(lin(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모듈 : 비선형 함수들 (Non-Linearities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-1.0246 -1.0300\n",
      "-1.0129  0.0055\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.0000  0.0000\n",
      "  0.0000  5.5350\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "-0.7717 -0.7739\n",
      "-0.7670  0.0055\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 0.2641  0.2631\n",
      " 0.2664  0.5014\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Variable( torch.randn(2, 2) )\n",
    "print(data)\n",
    "print(F.relu(data))\n",
    "print(F.tanh(data))\n",
    "print(F.sigmoid(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모듈 : Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.9347\n",
      "-0.9882\n",
      " 1.3801\n",
      "-0.1173\n",
      " 0.9317\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 0.0481\n",
      " 0.0456\n",
      " 0.4867\n",
      " 0.1089\n",
      " 0.3108\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-3.0350\n",
      "-3.0885\n",
      "-0.7201\n",
      "-2.2176\n",
      "-1.1686\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax is also in torch.functional\n",
    "data = Variable( torch.randn(5) )\n",
    "print(data)\n",
    "print(F.softmax(data))\n",
    "print(F.softmax(data).sum()) # Sums to 1 because it is a distribution!\n",
    "print(F.log_softmax(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(snn.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 예제 : BoW-Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import random\n",
    "import re\n",
    "import numpy\n",
    "from collections import Counter\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "tagger = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = open('./data/DOMAIN_10D_300EA_DATA_170427.txt','r',encoding='utf-8').readlines()\n",
    "data = [[d.split('\\t')[0],d.split('\\t')[1][:-1]] for d in data]\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['청천 나들이펜션 한들+후평나들이방 <br>8월 1314일예약해주세요<br> 010 2885 4816 <br>전화예약만받는다네요<br>예약좀해주세요ㅎ',\n",
       "  'HOTEL'],\n",
       " ['그럼. 음식점 퀵배달을 문비서를 통해 서비스신청을 하면 제때 이용 가능할지요. 제주도에는 위치나 시간에 따라 퀵서비스 이용에 제약이 많은것 같던데요.',\n",
       "  'QUICK'],\n",
       " ['예를들면 한국에 계신 부모님 꽃 배달 부탁이라던가', 'FLOWER'],\n",
       " ['앗. 퀵 취소 부탁 드려요', 'QUICK'],\n",
       " ['스시마츠모토 오늘 12시30분에 2인. 다이로 예약될까요?', 'RESTAURANT']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = zip(*data)\n",
    "X,y = list(X),list(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 간단한 전처리 후, Variable로 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 숫자 마스킹 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##월 ##일 크리스마스'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\d',\"#\",\"12월 25일 크리스마스\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,x in enumerate(X):\n",
    "    X[i] = re.sub('\\d',\"#\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['청천 나들이펜션 한들+후평나들이방 <br>#월 ####일예약해주세요<br> ### #### #### <br>전화예약만받는다네요<br>예약좀해주세요ㅎ',\n",
       " '그럼. 음식점 퀵배달을 문비서를 통해 서비스신청을 하면 제때 이용 가능할지요. 제주도에는 위치나 시간에 따라 퀵서비스 이용에 제약이 많은것 같던데요.',\n",
       " '예를들면 한국에 계신 부모님 꽃 배달 부탁이라던가',\n",
       " '앗. 퀵 취소 부탁 드려요',\n",
       " '스시마츠모토 오늘 ##시##분에 #인. 다이로 예약될까요?',\n",
       " '세금 계산서 발행 이체도 된다고 들었는데 사실 인가요?',\n",
       " '약간 이른데요. 오후 비행기는 없나요?',\n",
       " '동일한 비행기로 성인#명 초등학교 #학년 #명 비행기표 예매 부탁합니다.',\n",
       " '배송할께 있는데 어떻게 해야하나요? 경비실에 맡겨놓으면 픽업해가시나요?',\n",
       " '해외여행 페키지 상품 좀 알아봐주세요. 여행 가격은#인당 ##~ ##만원 / #박 #일 ~ #박 #일 / 인원 ## ~##명 / 출발일 ##월 말 ~ ##월 초']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [tagger.morphs(x) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 어휘 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4674"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(flatten(X)))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_frequency = Counter(flatten(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 1152),\n",
       " ('?', 1022),\n",
       " ('.', 780),\n",
       " ('는', 709),\n",
       " ('주', 694),\n",
       " ('br', 678),\n",
       " ('하', 637),\n",
       " ('##', 527),\n",
       " ('세요', 501),\n",
       " ('에', 499)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frequency.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = [w for w,f in vocab_frequency.items() if f==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index={}\n",
    "\n",
    "for vo in vocab:\n",
    "    if vo not in stopwords and vo not in word2index.keys():\n",
    "        word2index[vo]=len(word2index)\n",
    "        \n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2380"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target2index = {}\n",
    "\n",
    "for ta in list(set(y)):\n",
    "    if ta not in target2index.keys():\n",
    "        target2index[ta]=len(target2index)\n",
    "\n",
    "index2target = {v:k for k,v in target2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AIRPLANE': 0,\n",
       " 'FLOWER': 7,\n",
       " 'HOTEL': 2,\n",
       " 'INQUIRY': 4,\n",
       " 'OTHER': 3,\n",
       " 'PARCEL': 9,\n",
       " 'QUICK': 1,\n",
       " 'RESTAURANT': 6,\n",
       " 'SCHEDULE': 8,\n",
       " 'WEATHER': 5}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 스플릿 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(zip(X,y))\n",
    "\n",
    "train_data = data[:int(len(data)*0.9)]\n",
    "test_data = data[int(len(data)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        if word in word_to_ix.keys():\n",
    "            vec[word_to_ix[word]] += 1\n",
    "    return Variable(vec).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 1x2380]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_bow_vector(X[0],word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,(x,y) in enumerate(train_data):\n",
    "    train_data[i]= [make_bow_vector(x,word2index),Variable(torch.LongTensor([target2index[y]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "     0     0     0  ...      0     0     0\n",
       " [torch.FloatTensor of size 1x2380], Variable containing:\n",
       "  2\n",
       " [torch.LongTensor of size 1]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BoWClassifier 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,output_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        \n",
    "#         self.layer = nn.Linear(vocab_size,hidden_size)\n",
    "        self.outlayer = nn.Linear(vocab_size,output_size)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        \n",
    "#         out = F.relu(self.layer(inputs))\n",
    "        \n",
    "        return F.log_softmax(self.outlayer(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = BoWClassifier(len(word2index),len(target2index))\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0/300], loss : 2.33\n",
      "epoch [10/300], loss : 2.05\n",
      "epoch [20/300], loss : 1.89\n",
      "epoch [30/300], loss : 1.77\n",
      "epoch [40/300], loss : 1.68\n",
      "epoch [50/300], loss : 1.60\n",
      "epoch [60/300], loss : 1.53\n",
      "epoch [70/300], loss : 1.46\n",
      "epoch [80/300], loss : 1.40\n",
      "epoch [90/300], loss : 1.34\n",
      "epoch [100/300], loss : 1.28\n",
      "epoch [110/300], loss : 1.23\n",
      "epoch [120/300], loss : 1.18\n",
      "epoch [130/300], loss : 1.13\n",
      "epoch [140/300], loss : 1.09\n",
      "epoch [150/300], loss : 1.04\n",
      "epoch [160/300], loss : 1.00\n",
      "epoch [170/300], loss : 0.96\n",
      "epoch [180/300], loss : 0.93\n",
      "epoch [190/300], loss : 0.89\n",
      "epoch [200/300], loss : 0.86\n",
      "epoch [210/300], loss : 0.83\n",
      "epoch [220/300], loss : 0.80\n",
      "epoch [230/300], loss : 0.78\n",
      "epoch [240/300], loss : 0.75\n",
      "epoch [250/300], loss : 0.73\n",
      "epoch [260/300], loss : 0.70\n",
      "epoch [270/300], loss : 0.68\n",
      "epoch [280/300], loss : 0.66\n",
      "epoch [290/300], loss : 0.64\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP):\n",
    "    for i, (x,y) in enumerate(train_data):\n",
    "        model.zero_grad()\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_function(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if step % 10==0:\n",
    "        print('epoch [%d/%d], loss : %.2f' % (step,STEP,loss.data.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model/bowclassifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/bowclassifier.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.33333333333333\n"
     ]
    }
   ],
   "source": [
    "for test in test_data:\n",
    "    input_ = make_bow_vector(test[0],word2index)\n",
    "    pred = model(input_).max(1)[1] # greedy decoding\n",
    "    if test[1]==index2target[pred.data.tolist()[0]]:\n",
    "        accuracy+=1\n",
    "\n",
    "print(accuracy/len(test_data)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : 안녕 하 세요 ~ 비행기 표 구해 주 세요 < br > 제주 에서 서울 #/## ##.## 진에어 . 서울 에서 제주 #.## ## 시 ## 분 아시아 나\n",
      "ground truth : AIRPLANE\n",
      "prediction : AIRPLANE\n"
     ]
    }
   ],
   "source": [
    "random_test = random.choice(test_data)\n",
    "\n",
    "input_ = make_bow_vector(random_test[0],word2index)\n",
    "pred = model(input_).max(1)[1]\n",
    "\n",
    "print(\"input : %s\" % ' '.join(random_test[0]))\n",
    "print(\"ground truth : %s\" % random_test[1])\n",
    "print(\"prediction : %s\" % index2target[pred.data.tolist()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Next?! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/yunjey/pytorch-tutorial\n",
    "* https://github.com/rguthrie3/DeepLearningForNLPInPytorch/blob/master/Deep%20Learning%20for%20Natural%20Language%20Processing%20with%20Pytorch.ipynb\n",
    "* https://github.com/bharathgs/Awesome-pytorch-list\n",
    "* https://github.com/DSKSD/cs-224n-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
